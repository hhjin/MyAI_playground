{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c1f7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7249846e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "file = 'Tweets.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfaba30",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5ab657",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e200726",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[39m=\u001b[39m VectorstoreIndexCreator(\n\u001b[1;32m      2\u001b[0m     vectorstore_cls\u001b[39m=\u001b[39;49mDocArrayInMemorySearch\n\u001b[1;32m      3\u001b[0m )\u001b[39m.\u001b[39mfrom_loaders([loader])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:1066\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/fields.py:439\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.get_default\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34562d81",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "query =\"What is Open AI usages?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfd0cc37",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae21f1ff",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Open AI is a research organization focused on developing artificial intelligence technologies. They are best known for their work on generative models such as GPT-3 and their work on reinforcement learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631396c6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2164b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a977f44",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\\ufeffTweet: CHAT GPT几个相对实用的场景\\nProperty: https://twitter.com/vista8\\nCreated: June 9, 2023 12:38 PM\\nLink: \\nTags: Tool\\nTweet Link: https://twitter.com/vista8/status/1658508138050629632\\nType: Tweet', metadata={'source': 'Tweets.csv', 'row': 0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e875693a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "779bec75",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699aaaf9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d00d346",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.021913960576057434, 0.006774206645786762, -0.018190348520874977, -0.039148248732089996, -0.014089343138039112]\n"
     ]
    }
   ],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27ad0bb0",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0329bfd5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "query = \"What is the VR usage with LLM?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7909c6b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43321853",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eba90b5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\\ufeffTweet: 苹果官方介绍并没有把 #AppleVisionPro  定义为XR眼镜，操作系统也不是XrOS，苹果的定义是进入空间计算时代，连接数字世界和物理世界的桥梁。似乎苹果有着更大的野心和规划。\\nProperty: https://twitter.com/xiaohuggg\\nCreated: June 6, 2023 1:00 PM\\nLink: \\nTags: \\nTweet Link: https://twitter.com/xiaohuggg/status/1665896981259231232\\nType: Tweet', metadata={'source': 'Tweets.csv', 'row': 11})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0c3596e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0625f5e8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a573f58a",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffTweet: 终于，苹果最近发布的AR/VR职位描述里，总算泄露出来了他们要把LLM放进AR/VR设备里的想法：“Conversational and Generative AI”\\nProperty: https://twitter.com/fi56622380\\nCreated: June 7, 2023 7:49 PM\\nLink: \\nTags: \\nTweet Link: https://twitter.com/fi56622380/status/1665151979595898880\\nType: Thread\\ufeffTweet: 微调LLM+向量记忆索引+text to video+control net+deepfake换脸+声音克隆+LLM微调情绪标签，最后再加个高清VR。\\nProperty: https://twitter.com/goldengrape\\nCreated: June 7, 2023 6:37 AM\\nLink: \\nTags: Digitlife\\nTweet Link: https://twitter.com/goldengrape/status/1666134189488640000\\nType: Tweet\\ufeffTweet: 我把 AI 加入自己的工作流已经有段时间，现在基本是逢人就安利，建议尽快把 AI 介入开发流程。开一个 thread，分享下目前的一些经验、使用的工具和服务。截图这个基本就是我目前工作时的桌面状态。一般就是左边小窗开一个 ChatGPT ，右边VSCode + GitHub Copilot 插件。接下来展开讲讲。\\nProperty: https://twitter.com/luoleiorg\\nCreated: June 1, 2023 5:44 PM\\nLink: \\nTags: \\nTweet Link: https://twitter.com/luoleiorg/status/1662145013151858689\\nType: Thread\\ufeffTweet: 苹果官方介绍并没有把 #AppleVisionPro  定义为XR眼镜，操作系统也不是XrOS，苹果的定义是进入空间计算时代，连接数字世界和物理世界的桥梁。似乎苹果有着更大的野心和规划。\\nProperty: https://twitter.com/xiaohuggg\\nCreated: June 6, 2023 1:00 PM\\nLink: \\nTags: \\nTweet Link: https://twitter.com/xiaohuggg/status/1665896981259231232\\nType: Tweet'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n",
    "qdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14682d95",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: What is the VR usage with LLM?\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bba545b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Answer: The recent job description from Apple suggests that they plan to incorporate \"Conversational and Generative AI\" into their AR/VR devices, which could potentially involve using LLM technology. Additionally, another tweet mentions using LLM in combination with other technologies for text-to-video, deepfake, and emotion tagging in a VR context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32c94d22",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4769316",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "query =  \" What is the VR usage with LLM?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fc3c2f3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fba1a5db",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the first tweet, Apple's recent job description for AR/VR includes the idea of putting LLM (likely referring to the language model GPT-3) into their AR/VR devices with the goal of \"Conversational and Generative AI.\" However, the tweet does not provide specific details on how LLM will be used in VR."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "500ec062",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590b337",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "indexDefault = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n",
    "response = index.query(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2cb587c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "indexEmb = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])\n",
    "\n",
    "response = index.query(query )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec249f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d64f166",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The tweets suggest that Apple is planning to incorporate LLM into their AR/VR devices, and that AI can be used in development workflows to create high-definition VR experiences.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21322e7e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
